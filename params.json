{"name":"Related","tagline":"Tracks Frequently Related Items","body":"# ![Relateit](./relateitlogo.png)\r\n## (** \\*BETA\\* **)\r\n\r\n\r\n**relateit** is a simple and easy way to relate one item to several others.  Once several items are related, you can enquire:  \"For this item, what are the most frequently related items.\"\r\n\r\nAn example use case of this functionality is on a web site to associate the items the people are purchasing.  If a person purchases the books 'Java Performance Tuning', 'Akka Concurrency' and 'Java concurrency in practice' at the same time.  When a second user is browsing 'Java Performance Tuning', you can present that user with related items that this book is most frequently purchased with.  \r\n\r\nThis application has 3 parts to it:\r\n\r\n* A Indexing Web Application (Java)\r\n* A Searching Web Application (Java)\r\n* [Elasticsearch](http://www.elasticsearch.org/ \"Elasticsearch\") backend\r\n\r\nThe indexing and searching components (web applications) make use of the [Disruptor](https://github.com/LMAX-Exchange/disruptor \"Disruptor\") library.  \r\n\r\nThe search technology Elasticsearch provides the storage, and searching mechanism for providing the related product search.\r\n\r\nThe Indexing and Searching components do not need to directly be used.  In other words you can just post data in the relevant format into elasticsearch, and then perform searching directly against elasticsearch to obtain the most frequently related items.   However, it is the Indexing and Searching components that provide a means of batching indexing and searching requests that are being send to elasticsearch.\r\n\r\n----\r\n\r\n## Requirements ##\r\n\r\nJDK 7 (recommended jdk7u40+).\r\nJava Web Application Server (Tested on Tomcat).\r\nElasticsearch 0.90.9\r\n\r\n___\r\n\r\n## Indexing and Searching Overview ##\r\n\r\nThe index web application is POSTed data containing a group of related items, i.e. for example a purchase.  A post request is as follows:\r\n\r\n    curl -H\"Content-Type:text/json\" -XPOST -v http://localhost:8080/indexing/index -d '\r\n    {\r\n       \"channel\":\"de\",\r\n       \"site\":\"amazon\",\r\n       \"items\":[\r\n          {\r\n             \"id\":\"1\",\r\n             \"type\":\"map\"\r\n          },\r\n          {\r\n             \"id\":\"2\",\r\n             \"type\":\"compass\"\r\n          },\r\n          {\r\n             \"id\":\"3\",\r\n             \"type\":\"torch\"\r\n          },\r\n          {\r\n             \"id\":\"4\",\r\n             \"type\":\"torch\",\r\n             \"channel\":\"uk\"\r\n          }\r\n       ]\r\n    }'\r\n\r\n \r\nThe indexing application returns a 202 accepted status code to the client that issued the indexing request.  This indicate to the client that the request has been accepted for processing and indexing (this doesn't mean the json data is valid.  It just means the POST data is a valid binary payload).  \r\n\r\nIt is at this point the POSTed data is assembled into several documents.  For example, for the above request; 3 JSON documents will be assembled and submitted to elasticsearch for storage and indexing:\r\n\r\n    {\r\n        \"id\": \"1\" ,\r\n        \"date\": \"2013-12-24T17:44:41.943Z\",\r\n        \"related-with\": [ \"2\",\"3\",\"4\"],\r\n        \"type\": \"map\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"de\"\r\n    }\r\n\r\n    {\r\n        \"id\": \"2\" ,\r\n        \"date\": \"2013-12-24T17:44:41.943Z\",\r\n        \"related-with\": [ \"1\",\"3\",\"4\"],\r\n        \"type\": \"compass\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"de\"\r\n    }\r\n\r\n    {\r\n        \"id\": \"3\" ,\r\n        \"date\": \"2013-12-24T17:44:41.943Z\",\r\n        \"related-with\": [ \"1\",\"2\",\"4\"],\r\n        \"type\": \"torch\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"de\"\r\n    }\r\n    \r\n    {\r\n        \"id\": \"4\" ,\r\n        \"date\": \"2013-12-24T17:44:41.943Z\",\r\n        \"related-with\": [ \"1\",\"2\",\"3\"],\r\n        \"type\": \"torch\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"uk\"\r\n    }\r\n\r\nThe json element \"related-with\", will be used during search, to provide faceting information.  It is this facet that allows us to say:\r\n\r\n* For this id, what are the 5 top most frequently **related-with** ids.\r\n\r\nThe search web application is then called to request the frequently related items for a product (a GET request):\r\n\r\n    curl -v -N http://10.0.1.29:8080/searching/frequentlyrelatedto/1\r\n\r\nWhich returns json data containing the list of items (their id's) that are frequently related to that item:\r\n\r\n    {\r\n        \"response_time\": \"2\", \r\n        \"results\": [\r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"4\"\r\n            }, \r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"3\"\r\n            }, \r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"2\"\r\n            }\r\n        ], \r\n        \"size\": \"3\", \r\n        \"storage_response_time\": \"0\"\r\n}\r\n\r\nNote the search does not only provide the ability to search on the id.  It allows you to filter the result based on a property of the indexed document.  For example, from the initial POST there was 4 related items:\r\n\r\n* 3 of those had the property: **channel: de**\r\n* 1 of those had the property: **channel: uk**\r\n\r\nThe item that had overridden the **\"channel\"** property was the following:\r\n\r\n    {\r\n        \"id\": \"4\" ,\r\n        \"date\": \"2013-12-24T17:44:41.943Z\",\r\n        \"related-with\": [ \"1\",\"2\",\"3\"],\r\n        \"type\": \"torch\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"uk\"\r\n    }\r\n\r\nIn the above, there are 3 extra elements that can be searched on:\r\n\r\n* type\r\n* site\r\n* channel\r\n\r\nAs a result you can say.  Give with the frequently related product that are mostly purchased with product **1**, filtered the results to reduce to that of \"tourches\", i.e. type=torch:\r\n\r\n    curl -v -N http://10.0.1.29:8080/searching/frequentlyrelatedto/1?type=torch\r\n\r\nThe result is:\r\n\r\n    {\r\n        \"response_time\": \"11\", \r\n        \"results\": [\r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"4\"\r\n            }, \r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"3\"\r\n            }\r\n        ], \r\n        \"size\": \"2\", \r\n        \"storage_response_time\": \"2\"\r\n    }\r\n\r\nYou can go further and search for torches, just in channel uk, which is:\r\n\r\n    curl -v -N \"http://localhost:8080/searching/frequentlyrelatedto/1?type=torch&channel=uk\" | python -mjson.tool\r\n\r\nWhich will result in just the one related item:\r\n\r\n    {\r\n        \"response_time\": 3, \r\n        \"results\": [\r\n            {\r\n                \"frequency\": \"1\", \r\n                \"id\": \"4\"\r\n            }\r\n        ], \r\n        \"size\": \"1\", \r\n        \"storage_response_time\": 1\r\n    }\r\n\r\nCurrently the search result just returns the id's of the related items, and the frequency by which it was related with the searched for item it.   It *DOES NOT* return the matching document's information.  \r\n\r\nThe reason behind not returning the matching documents source, is that there could be literally hundreds of matching documents.  For example, the dvd \"The Raid\" could be bought many many times, with a range of other products.  For the below related item POSTs, the dvd \"The Raid\", is associated with \"Enter the dragon\" and \"kick boxer\".  Where the it is associated with \"kick boxer\" twice, and therefore \"kick boxer\" is the most frequently related item.  In the backend (elasticsearch), there are two actual physical documents that represent \"kick boxer\".  If we are to return the matching documents for the \"most frequently related\", we have to return the source both documents.  Expanding this further you could quite easily have a item related to another 100's of times; which would mean 100's of matching documents.  It is for this reason the content of that matches are not returned.\r\n\r\n    curl -H\"Content-Type:text/json\" -XPOST -v http://localhost:8080/indexing/index -d '\r\n    {\r\n       \"channel\":\"uk\",\r\n       \"site\":\"amazon\",\r\n       \"items\":[\r\n          {\r\n             \"id\":\"1\",\r\n             \"title\":\"The Raid\",\r\n             \"type\":\"dvd\"\r\n          },\r\n          {\r\n             \"id\":\"2\",\r\n             \"title\":\"Enter the dragon\",\r\n             \"type\":\"dvd\"           \r\n          }\r\n       ]\r\n    }'\r\n\r\n    curl -H\"Content-Type:text/json\" -XPOST -v http://localhost:8080/indexing/index -d '\r\n    {\r\n       \"channel\":\"uk\",\r\n       \"site\":\"amazon\",\r\n       \"items\":[\r\n          {\r\n             \"id\":\"1\",\r\n             \"title\":\"The Raid\",\r\n             \"type\":\"dvd\"\r\n          },\r\n          {\r\n             \"id\":\"2\",\r\n             \"title\":\"kick boxer\",\r\n             \"type\":\"dvd\"           \r\n          }\r\n       ]\r\n    }'\r\n    \r\n    curl -H\"Content-Type:text/json\" -XPOST -v http://localhost:8080/indexing/index -d '\r\n    {\r\n       \"channel\":\"uk\",\r\n       \"site\":\"amazon\",\r\n       \"items\":[\r\n          {\r\n             \"id\":\"1\",\r\n             \"title\":\"The Raid\",\r\n             \"type\":\"dvd\"\r\n          },\r\n          {\r\n             \"id\":\"2\",\r\n             \"title\":\"kick boxer\",\r\n             \"type\":\"dvd\"           \r\n          }\r\n       ]\r\n    }'\r\n\r\n___\r\n\r\n## More Indexing ##\r\n\r\nWhen a group of related items are indexed, by default they are stored in elasticsearch in a dated index, for example \"relateditems-YYYY-MM-DD\":\r\n\r\nEach date based index, is an index of it's own in elasticsearch.  If you were searching directly against elasticsearch you could independently search the one dated index.  \r\n\r\nThe date of the index is based on the UTC date of either:\r\n\r\n* The date contained within the RELATED ITEMS POST (converted to UTC)\r\n* The current date set on the server on which the indexing application is running.\r\n\r\nThe previous POST contained no date.  However, the following example POST contains a date that is in UTC timezone.  As an index named \"**relateditems-2013-12-25**\" will be created and the 4 related item documents indexed within that index.\r\n\r\n    {\r\n        \"channel\": \"de\", \r\n        \"date\": \"2013-12-25T09:44:41.943\", \r\n        \"items\": [\r\n            {\r\n                \"id\": \"1\", \r\n                \"type\": \"map\"\r\n            }, \r\n            {\r\n                \"id\": \"2\", \r\n                \"type\": \"compass\"\r\n            }, \r\n            {\r\n                \"id\": \"3\", \r\n                \"type\": \"torch\"\r\n            }, \r\n            {\r\n                \"channel\": \"uk\", \r\n                \"id\": \"4\", \r\n                \"type\": \"torch\"\r\n            }\r\n        ], \r\n        \"site\": \"amazon\"\r\n    }\r\n\r\n\r\nAs mentioned above, if the date in the related items POST contains a date with time zone information, it will be converted to UTC, and then the date used.  For example, the below POST contains:\r\n\r\n\r\n    \"date\": \"2013-12-24T09:44:41.943+10:00\"\r\n\r\nGiven this date, the 4 related item documents will be indexed within the index named:\r\n\r\n    relateditems-2013-12-23\r\n\r\nThe reason being that \"2013-12-24T09:44:41.943+10:00\" is \"2013-12-23T23:44:41.943\" in UTC timezone.  The resulting 4 related documents will contain the UTC timestamp.\r\n\r\n    {\r\n        \"channel\": \"de\", \r\n        \"date\": \"2013-12-24T09:44:41.943+10:00\", \r\n        \"items\": [\r\n            {\r\n                \"id\": \"1\", \r\n                \"type\": \"map\"\r\n            }, \r\n            {\r\n                \"id\": \"2\", \r\n                \"type\": \"compass\"\r\n            }, \r\n            {\r\n                \"id\": \"3\", \r\n                \"type\": \"torch\"\r\n            }, \r\n            {\r\n                \"channel\": \"uk\", \r\n                \"id\": \"4\", \r\n                \"type\": \"torch\"\r\n            }\r\n        ], \r\n        \"site\": \"amazon\"\r\n    }\r\n\r\nAn example document indexed in \"**relateditems-2013-12-23**\" looks as follows (taken from elasticsearch head):\r\n\r\n    {\r\n        _index: relateditems-2013-12-23\r\n        _type: related\r\n        _id: EmHW1qQBQv2BMgmQAlyMiA\r\n        _version: 1\r\n        _score: 1\r\n        _source: {\r\n            id: 3\r\n            date: 2013-12-23T23:44:41.943Z\r\n            related-with: [\r\n                4\r\n                1\r\n                2\r\n            ]\r\n            type: torch\r\n            site: amazon\r\n            channel: de\r\n        }\r\n    }\r\n\r\nThe document itself is:\r\n\r\n    {\r\n        \"id\": \"3\" ,\r\n        \"date\": \"2013-12-23T23:44:41.943Z\",\r\n        \"related-with\": [ \"4\",\"1\",\"2\"],\r\n        \"type\": \"torch\",\r\n        \"site\": \"amazon\",\r\n        \"channel\": \"de\"\r\n    }    \r\n\r\n\r\n----\r\n\r\n### Indexing and Searching Logging ###\r\n\r\nThe indexing and searching application uses log4j2, the default log configuration is as follows.  Log4j2 is used due to use of the disruptor framework to perform logging asynchronously.  In order for the default logging configuration to kick in the following property is required\r\n\r\n    -DLog4jContextSelector=\"org.apache.logging.log4j.core.async.AsyncLoggerContextSelector\"\r\n\r\nIf you don't like the look of the below configuration you can specify your own configuration file via:  \r\n\r\n    -Dlog4j.configurationFile=<absolute path to my file>\r\n\r\nIf the below configuration looks adequate, then you can customs the configurations with the following system properties:\r\n\r\n    -Drelated-item.searching.log.file=<absolute location of file>\r\n    -Drelated-item.searching.log.level=ERROR\r\n    -Drelated-item.indexing.log.file=<absolute location of file>\r\n    -Drelated-item.indexing.log.level=ERROR\r\n\r\nThe defaults are \"WARN\" and searching.log/indexing.log either in CATALINA_BASE/logs/ or java.io.tmpdir\r\n\r\nThe log4j2.xml configuration files are as follows:\r\n\r\n*Searching*\r\n\r\n```xml\r\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n    <configuration status=\"WARN\" monitorInterval=\"120\">\r\n        <appenders>\r\n            <RollingRandomAccessFile name=\"SEARCHING\" fileName=\"${sys:related-item.searching.log.file}\"\r\n                                 immediateFlush=\"false\" append=\"true\"\r\n                                 filePattern=\"${sys:related-item.searching.log.file}-%d{yyyy-MM-dd}-%i.log.gz\">\r\n                <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\r\n                <Policies>\r\n                    <TimeBasedTriggeringPolicy />\r\n                    <SizeBasedTriggeringPolicy size=\"50 MB\"/>\r\n                </Policies>\r\n            </RollingRandomAccessFile>\r\n        </appenders>\r\n        <loggers>\r\n            <root level=\"${sys:related-item.searching.log.level}\" includeLocation=\"false\">\r\n                <appender-ref ref=\"SEARCHING\"/>\r\n            </root>\r\n        </loggers>\r\n    </configuration>\r\n```\r\n\r\n*Indexing*\r\n\r\n```xml\r\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n    <configuration status=\"WARN\" monitorInterval=\"120\">\r\n        <appenders>\r\n            <RollingRandomAccessFile name=\"INDEXING\" fileName=\"${sys:related-item.indexing.log.file}\"\r\n                                 immediateFlush=\"false\" append=\"true\"\r\n                                 filePattern=\"${sys:related-item.indexing.log.file}-%d{yyyy-MM-dd}-%i.log.gz\">\r\n                <PatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/>\r\n                <Policies>\r\n                    <TimeBasedTriggeringPolicy />\r\n                    <SizeBasedTriggeringPolicy size=\"50 MB\"/>\r\n                </Policies>\r\n            </RollingRandomAccessFile>\r\n        </appenders>\r\n        <loggers>\r\n            <root level=\"${sys:related-item.indexing.log.level}\" includeLocation=\"false\">\r\n                <appender-ref ref=\"INDEXING\"/>\r\n            </root>\r\n        </loggers>\r\n    </configuration>\r\n```\r\n\r\n\r\n----\r\n\r\n### Indexes Searched Across by Default ###\r\n\r\nBy default the indexes that are searched in elasticsearch are any index that have a name starting with \"**relateditems-**\".  In other words a wild card search across all dated indexes starting with **relateditems-**\r\n\r\nThe prefix of the index name is controlled by the following configuration parameter.  A hyphen \"-\", will added to the end of the prefix, and any subsequent indexing will index documents into a dated index:\r\n\r\n    -Drelated-item.storage.index.name.prefix\r\n\r\nFor example with the setting:\r\n\r\n    -Drelated-item.storage.index.name.prefix=related\r\n\r\nDocuments will be indexed and Searching in/from indexes named: \"**related-YYYY-MM-DD**\".\r\n\r\nIt is also possible to use an alias against which to perform searches, rather than performing a wild search search. (**note** The alias does not apply to indexing).\r\n\r\nThe below gives an example of the curl request used to set up an index in elasticsearch.  It creates an alias \"**related**\"\", which is an alias for the indexes: \"**relateditems-2013-12-23**\" and \"**relateditems-2013-12-24**\".  When \"**related**\" is used to search, the search will be performed only against those two indexes.\r\n\r\n    curl -XPOST localhost:9200/_aliases -d '\r\n    {\r\n        \"actions\": [\r\n            { \"add\": {\"alias\": \"related\", \"index\": \"relateditems-2013-12-23\"} },\r\n            { \"add\": { \"alias\": \"related\",\"index\": \"relateditems-2013-12-24\"} }\r\n        ]\r\n    }'\r\n\r\nTo tell the Search Web Application to use that alias, instead of the wildcard index search, you specify the alias name using the following parameter:\r\n\r\n    -Drelated-item.storage.index.name.alias=related\r\n\r\n#### Why Use an Alias? ####\r\n\r\nAn alias can give you added flexibility over the content that is being searched.  However, this comes at the cost of added complexity from having to maintain the alias. \r\n\r\nAn example usage for an alias could be the following.  Imagine one day you are having a promotion for a new selection of products.  You could choose to promote those products against a selection of other products.  One way to do this is to re-associate the alias to a prepared index of those products and the associated items:\r\n\r\n    curl -XPOST localhost:9200/_aliases -d '\r\n    {\r\n        \"actions\": [\r\n            { \"add\" :   { \"alias\" : \"related\", \"index\": \"promotion-2013-12-25\"   } },\r\n            { \"remove\": { \"alias\" : \"related\", \"index\": \"relateditems-2013-12-23\"} },\r\n            { \"remove\": { \"alias\" : \"related\", \"index\": \"relateditems-2013-12-24\"} }\r\n        ]\r\n    }'\r\n\r\nThe above removes the existing mappings and creates the new mapping.  This can be done a runtime, without starting either elasticsearch or the searching application.  However, the downside here is the maintenance of the alias.  \r\n\r\nThe alias cannot use a wildcard, and it needs to point to a valid index that exists.  Therefore, a maintenance script needs to create that would periodically run to update the alias mapping to point to new indexes.\r\n\r\nUnfortunately at the moment support for assigning index alias's at index creation time does not currently exist (https://github.com/elasticsearch/elasticsearch/pull/2739 and https://github.com/elasticsearch/elasticsearch/issues/4920).\r\n\r\nFor more information about index alias in elasticsearch please read:\r\n\r\n    http://www.elasticsearch.org/blog/changing-mapping-with-zero-downtime/\r\n\r\n\r\n____\r\n\r\n### Post Document Format ###\r\n\r\nThe related items document that is POST'ed to the indexing web application has a couple of keys that it refers to:\r\n\r\n* \"**items**\": An array of items that are related, i.e. just been purchased together\r\n* \"**id**\":    The id of the item, this is your identify for the item, for example the Product Id.\r\n* \"**date**\":  The date at which the related items were created, i.e. the purchase time\r\n\r\nExample:\r\n\r\n    {\r\n        \"date\": \"2013-12-24T09:44:41.943+10:00\", \r\n        \"items\": [\r\n            {\r\n                \"id\": \"1\"      \r\n            }, \r\n            {\r\n                \"id\": \"2\" \r\n            } \r\n        ] \r\n    }\r\n \r\nOr in short form:\r\n\r\n    {\r\n        \"date\": \"2013-12-24T09:44:41.943+10:00\", \r\n        \"items\": [ \"1\",\"2\" ]\r\n    }\r\n\r\nThe short form of the post makes the assumption that the strings in the \"**items**\" array are the \"**id**\"'s \r\n\r\nAs previously seen the indexing POST document can contain extra keys and values that are associated to either the related items POST in it's entirety, or can be specific to a particular item in the related items document.\r\n\r\nFor example:\r\n\r\n    {\r\n        \"date\": \"2013-12-24T09:44:41.943+10:00\", \r\n        \"site\": \"amazon\", \r\n        \"channel\" : \"uk\",       \r\n        \"items\": [\r\n            {\r\n                \"department\" : \"electronics\",\r\n                \"category\" : \"storage\",\r\n                \"type\" : \"hard disk\",\r\n                \"id\": \"1\",      \r\n            }, \r\n            {\r\n                \"department\" : \"electronics\",\r\n                \"category\" : \"notebooks\",\r\n                \"type\" : \"macbook pro\",\r\n                \"memory\" : \"8gb\",\r\n                \"channel\" : \"de\",\r\n                \"id\": \"2\", \r\n            } \r\n        ] \r\n    }\r\n\r\nGiven the above the key/value: **\"site\": \"amazon\"**, will apply to all the related item documents that are indexed in elasticsearch (2 documents in the above).  The key/value pairs within the \"items\" array will apply just to that item's document that is indexed.  \r\n\r\nDocument with \"id\": \"1\" will have the key/values:\r\n\r\n    \"date\": \"2013-12-23T23:44:41.943\"\r\n    \"site\": \"amazon\", \r\n    \"channel\" : \"uk\",    \r\n    \"department\" : \"electronics\",\r\n    \"category\" : \"storage\",\r\n    \"type\" : \"hard disk\",    \r\n\r\nDocument with \"id\" : \"2\" will have the key/values:\r\n\r\n    \"date\": \"2013-12-23T23:44:41.943\"\r\n    \"site\": \"amazon\", \r\n    \"channel\" : \"de\",    \r\n    \"department\" : \"electronics\",\r\n    \"category\" : \"notebooks\",\r\n    \"type\" : \"macbook pro\",\r\n    \"memory\" : \"8gb\"\r\n\r\nIf an element exist in the item's property that was defined in the parent enclosing document, then the item's value takes precedence and overrides that of the enclosing document's setting.\r\n\r\nWith the above you can see that the second item has an extra field \"memory\", than that of the first document.  Whilst it does not make much difference to the backend (elasticsearch) or the web applications (searching or indexing), for consistencies sake you shouldn't really have key existing in one related item that do not appear in the.  However, it is entirely up to you.  \r\n\r\n### How Many Items Can Be Included in a Single Related Item POST? ###\r\n\r\nBy fault 10 related items per POST request can be handled.  By default if there are 11 items in the indexing request; the last item is silently ignored (a warning is output in the logs).  The below are the properties that are available for configuration, for adjusting these defaults\r\n\r\n    * related-item.max.number.related.items.per.index.request = 10\r\n    * related-item.max.related.item.post.data.size.in.bytes = 10240\r\n    * related-item.indexing.discard.storage.requests.with.too.many.relations = false\r\n\r\n### How Many Properties Can I Have for Related Item ###\r\n\r\nThe answer to this question is that you can have as many properties as you like per indexed relate item.  However, in order to have as many items as you like you need to pay for that, in terms of memory allocated to the application, or reduction in the ring buffer size, and or length of the property keys/values.\r\n\r\nThe following properties are available for configuration, show with their defaults.  As a result if you know a related item will have more than 10 properties (remember this leaves you with 7 configurable properties of your choosing; id, date and related-with take already taken)\r\n\r\n    * related-item.max.number.related.item.properties = 10\r\n    * related-item.additional.prop.key.length = 30 (characters)\r\n    * related-item.additional.prop.key.length = 30 (characters)\r\n    * related-item.indexing.size.of.incoming.request.queue = 16384\r\n    \r\n___\r\n\r\n## Elasticsearch ##\r\n\r\nAs mentioned above, the related item data is stored in elasticsearch and the ability to find the frequently related items, for an item, is provided by that of elasticsearch and its faceting.  \r\n\r\nThe indexing and searching web applications use the elasticsearch java library.  \r\n\r\nThe means by which the indexing and searching applications talk to elastic is by using the elasticsearch binary transport protocol.  Meaning, the version of the client embedded within the web applications (indexing and searching), *MUST* match that of the elasticsearch server.  Also, the version of JAVA on the client and the server *MUST* be the same.\r\n\r\n    * Current embedded elasticsearch version is: **0.90.9**\r\n\r\nBy default both applications use the Transport protocol to connect to elasticsearch with sniffing enabled:\r\n\r\n    * client.transport.sniff : true\r\n\r\n(Sniffing means that you can specify only a couple of hosts, and the client will glen information on the rest of the cluster through those nodes).\r\n\r\nThe reason behind no support for HTTP endpoint is just to focus on using the most performant client option, which is that of the transport client.  HTTP support is on the list of things to enable, but it would require either extra configuration at your side (i.e. a load balancer), or for the application to provide a simple round robin implementation to round robin request over a list of nodes.  So at the moment only the \"**node**\", or \"**transport**\" option are available.  With the default being that of **transport**.\r\n\r\n----\r\n### Elasticsearch Connection Configuration ##\r\n\r\nThe defaults for indexing and searching have been set based on a JVM the is running 1GB with 128m of PermGen (The specific configuration for these JVM Parameters can be found below).\r\n\r\nAt minimum the only configuration required is the connection details for your elasticsearch installation:\r\n\r\n    * related-item.elastic.search.transport.hosts=10.0.1.19:9300\r\n\r\nThis can be a comma separated list of hosts:\r\n\r\n    * related-item.elastic.search.transport.hosts=10.0.1.19:9300,10.0.1.29:9300\r\n\r\nBy default the application uses the TRANSPORT client to connect to elastic search.  If you only specify one host, but you have 2 nodes in your elasticsearch cluster, the transport client is enabled by default to sniff (ask the node for information about other nodes in the cluster), and obtain a list of other nodes to connect to.\r\n\r\n----\r\n\r\n### Elasticsearch Relate Item Type Mapping\r\n\r\nWhen the indexing and searching applications talk to elasticsearch they search for documents within the index \"relateditems-YYYY-MM-DD\" for the document type \"related\".  As previously mentioned the defined properties require for the \"related\" type are: \r\n\r\n* id \r\n* related-with\r\n* date\r\n\r\nWhen indexing documents in elasticsearch, if a type (i.e. \"related\") does not have an associated mapping then a dynamic mapping of a document's json properties are created.  Which may or may not be what is required.  As a result, you should define a mapping for the type.  The mapping for the related type should at minimum be the following:\r\n\r\n    curl -XPUT http://localhost:9200/_template/relateditems -d '{\r\n        \"template\" : \"relateditems*\",\r\n        \"settings\" : {\r\n            \"number_of_shards\" : 1,\r\n            \"number_of_replicas\" : 1,\r\n            \"index.refresh_interval\" : \"5s\",\r\n            \"index.store.compress.stored\" : false,\r\n            \"index.query.default_field\" : \"id\",\r\n            \"index.routing.allocation.total_shards_per_node\" : 1,\r\n            \"indices.memory.index_buffer_size\" : 30\r\n        },\r\n        \"mappings\" : {\r\n            \"related\" : {\r\n               \"_all\" : {\"enabled\" : false},\r\n               \"dynamic\" : false,\r\n               \"properties\" : {\r\n                  \"id\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"store\" : \"yes\" },\r\n                  \"related-with\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"store\" : \"yes\" },\r\n                  \"date\": { \"type\": \"date\", \"index\": \"not_analyzed\", \"store\" : \"no\" }\r\n               }\r\n            }\r\n        }\r\n    }'\r\n\r\nIf the related documents you are indexed are going to have more properties (i.e. channel, type, etc).  You need to expand upon the mapping above to detail those properties.  A guide to mapping can be found [In the following elasticsearch documentation](http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/mapping-core-types.html)\r\n\r\n    curl -XPUT http://10.0.1.19:9200/_template/relateditems -d '{\r\n        \"template\" : \"relateditems*\",\r\n        \"settings\" : {\r\n            \"number_of_shards\" : 1,\r\n            \"number_of_replicas\" : 1,\r\n            \"index.refresh_interval\" : \"5s\",\r\n            \"index.store.compress.stored\" : false,\r\n            \"index.query.default_field\" : \"id\",\r\n            \"index.routing.allocation.total_shards_per_node\" : 1,\r\n            \"indices.memory.index_buffer_size\" : 30\r\n        },\r\n        \"mappings\" : {\r\n            \"related\" : {\r\n               \"_all\" : {\"enabled\" : false},\r\n               \"dynamic\" : false,\r\n               \"properties\" : {\r\n                  \"id\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"store\" : \"yes\" },\r\n                  \"related-with\": { \"type\": \"string\", \"index\": \"not_analyzed\", \"store\" : \"yes\" },\r\n                  \"date\": { \"type\": \"date\", \"index\": \"not_analyzed\", \"store\" : \"no\" },\r\n                  \"channel\" : {\"type\" : \"string\" , \"index\" : \"not_analyzed\", \"store\" : \"no\" },\r\n                  \"site\" : {\"type\" : \"string\" , \"index\" : \"not_analyzed\", \"store\" : \"no\" },\r\n                  \"type\" : {\"type\" : \"string\" , \"index\" : \"not_analyzed\", \"store\" : \"no\" }\r\n               }\r\n            }\r\n        }\r\n    }'\r\n\r\n\r\n\r\n### Elasticsearch Server Configuration ###\r\n\r\nThe elasticsearch server itself also requires some configuration.  By default out of the box elastic search will use multicast to locate other nodes in the cluster, and will locally store indexes inside the *data/* directory in it's download installation location.  You more than like want to:\r\n\r\n    * Move to unicast if your network does not cope with multicast traffic routing well (i.e. multiple data centres, etc.)\r\n    * Move the local storage to a raid array, with raid 1, 5 or raid 1+0 (10), away from the data/ directory.  So that you can update the elasticsearch binaries without affecting the data indexed.\r\n\r\nThe elasticsearch configuration file (**config/elasticsearch.yml**), needs to be updated to reflect the default cluster name that the indexing and searching application will be looking for the elasticsearch cluster/nodes to be operating with (the default being \"**relateditems**\").  The name of the cluster is controlled by the following property on the Searching or Indexing web application:\r\n\r\n    * related-item.storage.cluster.name\r\n\r\nTherefore the elasticsearch configuration (**config/elasticsearch.yml**) should have the following set:\r\n \r\n    cluster.name: relateditems\r\n\r\nThere are several other properties that are not by default in the elasticsearch.yml file, that assist in its operations (searching, bulk operations, getting and indexing).  The following configuration reduces the size of the queue, and the maximum number of threads that elasticsearch can run of the given operations.  By changing the defaults we are allowing existing operations to complete, without flooding it with more requests until it is unable to cope with the load.  As a result we bound the size of the pools and queues, in order to apply back pressure to the request's origin (I.e. The search application and the indexing application)\r\n\r\nThese pool settings are as follows.  The settings a highly dependent upon the size of your elastic search cluster.  This is just a set of recommendations.\r\n\r\n### Search pool\r\n\r\n    threadpool.search.type: fixed\r\n    threadpool.search.size: 20\r\n    threadpool.search.queue_size: 100000\r\n\r\n### Bulk pool\r\n    threadpool.bulk.type: fixed\r\n    threadpool.bulk.size: 25\r\n    threadpool.bulk.queue_size: 100000\r\n\r\n### Get Pool\r\n    threadpool.get.type: fixed\r\n    threadpool.get.size: 1\r\n    threadpool.get.queue_size: 1\r\n\r\n### Index pool\r\n    threadpool.index.type: fixed\r\n    threadpool.index.size: 20\r\n    threadpool.index.queue_size: 100000\r\n----\r\n\r\n## JVM Options and Configuration Defaults #\r\n\r\nThe default configuration for indexing and searching are based on a 1GB heap\r\n(-Xmx1024m -Xms1024m) configuration.  It is for this default configuration\r\nthat the below JVM options and Heap configuration is specified.\r\n\r\nThe specific recommended (tested against) JVM options for searching and indexing\r\nare listed below (jdk7 - the following options *WILL NOT* work on jdk6).\r\nThe JVM options slightly differ between searching and indexing.  The common options\r\nare listed and then the differences listed:\r\n\r\n### Common options for Web Applications\r\n\r\n    -XX:CMSInitiatingOccupancyFraction=85\r\n    -XX:MaxTenuringThreshold=15\r\n    -XX:CMSWaitDuration=70000    \r\n    -XX:MaxPermSize=128m\r\n    -XX:ParGCCardsPerStrideChunk=4096\r\n    -XX:+UseParNewGC\r\n    -XX:+UseConcMarkSweepGC\r\n    -XX:+UseCMSInitiatingOccupancyOnly    \r\n    -XX:+UnlockDiagnosticVMOptions\r\n    -XX:+AggressiveOpts\r\n    -XX:+UseCondCardMark\r\n\r\n----\r\nBelow shows the heap configuration for indexing and search.  The difference between\r\nthe two is that of the eden space.\r\n\r\n### Searching Heap ###\r\n\r\n    -Xmx1024m\r\n    -Xmn700m\r\n    -Xms1024m\r\n    -Xss256k\r\n\r\n### Indexing Heap ###\r\n\r\n    -Xmx1024m\r\n    -Xmn256m\r\n    -Xms1024m\r\n    -Xss256k\r\n\r\n----\r\n\r\n\r\n## Application Configuration ##\r\n\r\nThe Searching and Indexing web applications can be configured via a wide range of properties.  These can either be set using System Properties:\r\n\r\n* -Drelated-item.max.number.related.item.propetties=10\r\n\r\nOr by using a yaml configuration file.  The following will list all the properties that are available for configuration, along with their use.  Some properties are specifically for searching, others specifically for indexing, and others for both.  This will be noted.\r\n\r\n\r\n| Property Name   | usage | Searching/Indxing/ALL |\r\n| ----------------| ----- | --------------------- |\r\n* related-item.safe.to.output.index.request.data | Writes to logs (when DEBUG) the index request data | Indexing |\r\n* related-item.max.number.related.item.properties | The max number of properties a related item can have.  More properties than this will be silently discarded.  There is no guarantee of ordering | Indexing | \r\n* related-item.max.number.related.items.per.index.request | The max number of related items in a single index POST request | Indexing |\r\n* related-item.related.item.id.length | The max number of characters that the \"id\" of a related items can have | All |\r\n* related-item.max.related.item.post.data.size.in.bytes | max size in bytes of the POST data for an index request| Indexing |\r\n* related-item.min.related.item.post.data.size.in.bytes | The minimum size, in bytes, of the POSTed json data for an index request | Indexing |\r\n* related-item.additional.prop.key.length | The max number of characters a property name can have| All |\r\n* related-item.additional.prop.value.length | the max number of characters a property value can have | All |\r\n* related-item.indexing.size.of.incoming.request.queue | Size of the ring buffer that accepts incoming indexing POST requests | Indexing |\r\n* related-item.indexing.size.of.batch.indexing.request.queue  | The size of the ring buffer for each indexing processor that batch posts indexing requests to elasticsearch | Indexing |\r\n* related-item.indexing.batch.size | The max number of related item objects (a single index request will have many related item objects), that can be sent for batching indexing to elastic search.| Indexing |\r\n* related-item.searching.size.of.related.content.search.request.queue | Size of the ring buffer that accepts incoming search requests | Searching |\r\n* related-item.searching.size.of.related.content.search.request.handler.queue | Size of the ring buffer for each search processor that submits search requests to elasticsearch | Searching |\r\n* related-item.searching.size.of.related.content.search.request.and.response.queue | Size of the ring buffer that is used to store incoming Request AsyncContext objects for later retrieval | Searching |\r\n* related-item.searching.max.number.of.search.criteria.for.related.content | number of additional properties that will be searched on | Searching |\r\n* related-item.searching.number.of.expected.like.for.like.requests | The number of search request that we expect to be similar| Searching |\r\n* related-item.searching.key.for.frequency.result.id | The key used for the id field in the search result json| Searching |\r\n* related-item.searching.key.for.frequency.result.occurrence | The key used for the frequency in the search results json | Searching |\r\n* related-item.searching.key.for.storage.response.time | Key used to represent how long the elasticsearch request took, in the json response doc | Searching | \r\n* related-item.searching.key.for.search.processing.time | Key used to represent how long the complete search request took.  It is the key used in the response json | Searching |\r\n* related-item.searching.key.for.frequency.result.overall.no.of.related.items | key in the search response used to represent the number of frequencies returned | Searching |\r\n* related-item.searching.key.for.frequency.results | key in the search response json under which the frequencies are found | Searching |\r\n* related-item.searching.request.parameter.for.size | request parameter used to specify the max number of frequencies to return| Searching | \r\n* related-item.searching.request.parameter.for.id | parameter used to associate the id in a map of request parameters | Searching |\r\n* related-item.searching.default.number.of.results | default number of search result (frequencies) to return | Searching |\r\n* related-item.searching.size.of.response.processing.queue | size of ring buffer for processing search results and sending json response to the awaiting AsyncContext | Searching |\r\n* related-item.indexing.number.of.indexing.request.processors | number of processors used to perform indexing (sending batch indexing requests) to elasticsearch | Indexing | \r\n* related-item.searching.number.of.searching.request.processors | The number of ring buffers (processors) that will be sending search requests to elasticsearch | Searching |\r\n* related-item.storage.index.name.prefix | The name of the index used in elasticsearch for storing related item documents (i.e. relateditems-<YYYY-MM-DD>) | All |\r\n* related-item.storage.index.name.alias | The name of the index alias against which to search (http://www.elasticsearch.org/blog/changing-mapping-with-zero-downtime/) | All |\r\n* related-item.storage.content.type.name | The index type | All |\r\n* related-item.storage.cluster.name | The name of the elasticsearch cluster | All |\r\n* related-item.storage.frequently.related.items.facet.results.facet.name | The property used for naming the facet during the search request to elastic search  | Searching |\r\n* related-item.storage.searching.facet.search.execution.hint | Used during search request to elastic search.  The setting of 'map' is the default.  Makes request much much faster | Searching |\r\n* related-item.indexing.key.for.index.request.related.with.attr | The key used in the indexed document for the storing the related ids | All |\r\n* related-item.indexing.key.for.index.request.date.attr | The key used in the indexed document for the date attribute | All |\r\n* related-item.indexing.key.for.index.request.id.attr | The key against which the id is stored in the indexed document | All |\r\n* related-item.indexing.key.for.index.request.item.array.attr | The key in the incoming user json indexing request that contains the list of items | All |\r\n* related-item.elastic.search.client.default.transport.settings.file.name | name of the elastic search file containing the transport client settings (defaults) | All |\r\n* related-item.elastic.search.client.default.node.settings.file.name | name of the elasticsearch file containing the node client settings (defaults) | All |\r\n* related-item.elastic.search.client.override.settings.file.name | name of the elasticsearch file than can be distributed to override the default node/transport settings | All |  \r\n* related-item.searching.frequently.related.search.timeout.in.millis | timeout in millis for elasticsearch requests | All |\r\n* related-item.storage.location.mapper | day/hour/min used to convert date to a string used for creating the index name in which documents are stored | All |\r\n* related-item.searching.timed.out.search.request.status.code | the http status code when a timeout occurs | Searching |\r\n* related-item.searching.failed.search.request.status.code | the http status code when a search request fails to talk to elasticsearch | Searching |\r\n* related-item.searching.not.found.search.request.status.code | the http status code when no search result is found | Searching |\r\n* related-item.searching.found.search.results.handler.status.code | the http status code when a match is found | Searching |\r\n* related-item.searching.missing.search.results.handler.status.code | the http status code when we cannot handle the json search response | Searching |\r\n* related-item.wait.strategy | The type of ring buffer wait strategy: yield/busy/sleep/block | All |\r\n* related-item.es.client.type | The type of elasticsearch client to use | All |\r\n* related-item.indexing.indexname.date.caching.enabled | caching of index date | All |\r\n* related-item.indexing.number.of.indexname.to.cache | number of index names to cache | All |\r\n* related-item.indexing.replace.old.indexed.content | replace existing content (false) | Indexing | \r\n* related-item.use.separate.repository.storage.thread | Use a separate thread for performing indexing | Indexing |\r\n* related-item.indexing.discard.storage.requests.with.too.many.relations | silently discard related items in the indexing request it there are too many.  Indexes up to the max, discards the others | Indexing |\r\n* related-item.elastic.search.transport.hosts | The host:port,host:port contain the unicast addresses of the search nodes in elastic search to talk to | All |\r\n* related-item.elastic.search.default.port | the default port if not specified to talk to in elasticsearch | All |\r\n* related-item.searching.use.shared.search.repository | Whether the search processors use a shared connection to elastic search | Searching | \r\n* related-item.searching.response.debug.output.enabled | output the response json being sent to the client, also to a log file.  | Searching |\r\n\r\n\r\nBy default the Searching and Indexing web applications will look for a yaml configuration file from which to load the configuration details.  Any settings in the configuration file, override the defaults.  Any system properties set will override the settings that are contained within the yaml configuration.  \r\n\r\nBy default the yaml file **related-items.yaml** is looked for on the class path.  The location of the file can be specified by the property, **related-items.settings.file**, for example:\r\n\r\n* -Drelated-items.settings.file=/etc/relateditems.yml\r\n\r\nThe yaml file, may look like the following:\r\n\r\n    related-item:\r\n           searching:\r\n                  number.of.searching.request.processors: 16\r\n                  size.of.related.content.search.request.handler.queue: 1024\r\n\r\n           indexing:\r\n                  size.of.batch.indexing.request.queue: 4096\r\n\r\n\r\nWith the above in place the following properties are overridden:\r\n\r\n* related-item.searching.number.of.searching.request.processors\r\n* related-item.searching.size.of.related.content.search.request.handler.queue\r\n* related-time.indexing.size.of.batch.indexing.reqeust.queue\r\n\r\nIf a system properties was set (-Drelated-item.searching.number.of.searching.request.processors=2), that would override the setting in the yaml file.\r\n\r\n----\r\n\r\n## Searching and Indexing Architecture ##\r\n\r\nThe below shows a couple of simple high level architecture diagrams for the indexing and searching.\r\n\r\n#### Searching ####\r\n\r\n![Search Application Architecture](./SearchExecutionArch.png)\r\n\r\n#### Indexing ####\r\n\r\n\r\n![Index Application Architecture](./IndexExecutionArch.png)\r\n\r\n\r\n## Load Testing ##\r\n\r\nBelow show the load testing results from indexing and searching tests performed against the application during development and testing.  You will obviously have different results based on your representative indexing data and searches.  \r\n\r\nThe load tests results are from running a 1GB heap and running indexing and searching completely independently of each other.\r\n\r\nElasticsearch version 0.90.9 is running on 2 hosts:\r\n\r\n* Mac mini 2.3 GHz Core i5 (I5-2415M)\r\n* macbook pro 17\" 2.5 GHz Core i7 (I7-2860QM) \r\n\r\nThe indexing and searching applications are running on:\r\n\r\n* Dell poweredge t420, 2 cpu Intel(R) Xeon(R) CPU E5-2407 2.20GHz.\r\n* tomcat 7u42, NIO connector.\r\n* centos 6.5\r\n\r\nThe connection between the dell t420 and the macbook pro is wifi 5g, and to mac mini 100mbps lan.\r\nThe gatling load test is run on another host, running 1000 concurrent users.\r\n\r\n--- \r\n### Indexing Load Test Output ###\r\n\r\n    ================================================================================\r\n    ---- Global Information --------------------------------------------------------\r\n    > numberOfRequests                                 2346426 (OK=2346426 KO=0     )\r\n    > minResponseTime                                        0 (OK=0      KO=-     )\r\n    > maxResponseTime                                     1570 (OK=1570   KO=-     )\r\n    > meanResponseTime                                       3 (OK=3      KO=-     )\r\n    > stdDeviation                                          29 (OK=29     KO=-     )\r\n    > percentiles1                                          10 (OK=10     KO=-     )\r\n    > percentiles2                                          10 (OK=10     KO=-     )\r\n    > meanNumberOfRequestsPerSecond                       3351 (OK=3351   KO=-     )\r\n    ---- Response Time Distribution ------------------------------------------------\r\n    > t < 800 ms                                       2345586 ( 99%)\r\n    > 800 ms < t < 1200 ms                                  82 (  0%)\r\n    > t > 1200 ms                                          758 (  0%)\r\n    > failed                                                 0 (  0%)\r\n    ================================================================================\r\n----\r\n### Searching Load Test Output ###\r\n\r\n    ================================================================================\r\n    ---- Global Information --------------------------------------------------------\r\n    > numberOfRequests                                 3350140 (OK=3350140 KO=0     )\r\n    > minResponseTime                                        0 (OK=0      KO=-     )\r\n    > maxResponseTime                                     4310 (OK=4310   KO=-     )\r\n    > meanResponseTime                                      76 (OK=76     KO=-     )\r\n    > stdDeviation                                         110 (OK=110    KO=-     )\r\n    > percentiles1                                         140 (OK=140    KO=-     )\r\n    > percentiles2                                         470 (OK=470    KO=-     )\r\n    > meanNumberOfRequestsPerSecond                       4785 (OK=4785   KO=-     )\r\n    ---- Response Time Distribution ------------------------------------------------\r\n    > t < 800 ms                                       3335529 ( 99%)\r\n    > 800 ms < t < 1200 ms                               11950 (  0%)\r\n    > t > 1200 ms                                         2661 (  0%)\r\n    > failed                                                 0 (  0%)\r\n    ================================================================================\r\n\r\n","google":"UA-47714522-1","note":"Don't delete this file! It's used internally to help with page regeneration."}